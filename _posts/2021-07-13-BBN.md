---
layout: post
title: Bilateral-Branch Network with Cumulative Learning
---

## Paper Information

**Title:** BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition

**Authors:** Boyan Zhou, Quan Cui, Xiu-Shen Wei, and Zhao-Min Chen

**Conference:** Conference on Computer Vision and Pattern Recognition 2020

**Pages:** 9716-9725

**Year:** 2020

**Link:** [https://arxiv.org/pdf/1912.02413.pdf](https://arxiv.org/pdf/1912.02413.pdf)

## Paper Summary

*BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition* presents a framework to separate learning representations from classifiers in order to increase classifier performance on "long-tailed", or underrepresented, classes. The authors created the framework after experimenting with different variations of fixing representation and classifier learning separately. The proposed framework consists of a neural network with three parts: a representation branch, a classifier branch, and a cumulative learning part that combines results from both together. The framework is then compared to previous work, showing promise against nearly every compared dataset. 

The primary difference between the two branches of the neural network is their training regimen, leaving a desired effect during testing and general inferencing. For each iteration of training, each branch is given a different sample in accordance with a specific sampling scheme. For the branch responsible for representation learning, samples are selected based off of the as-is data distribution. As there is no modification to how exactly samples are selected, the branch is also known as the conventional learning branch. Conversely, the branch responsible for learning the classifier, also known as the re-balancing branch, is given samples based off of a reversed sampler. For example, if class A makes up 90 percent and class B makes up the remaining 10 percent of the training data, samples from class A are picked 10 percent and those from class B are picked 90 percent of the time for the re-balancing branch. Additionally, weights within the hidden layers are shared amongst the two branches.

To combine the results from the conventional and re-balancing branches, a cumulative learning strategy is employed. Before the output is generated, each branch output is multiplied by an iteration-varying coefficient, which is then considered the input for the output layer. These results are multiplied by their respective weight matrices, summed up, and finally go through a softmax activation function. The resulting error function is defined by a sum of the errors of each respective network, with each being multiplied by their same aforementioned iteration-varying coefficient. The coefficient acts in a way, such that at the beginning of training, the error function is solely the error from the conventional branch; at the end, the converse is true. Since the coefficient varies quadratically, the training focuses more on the representation learning first, then quickly emphasizes classifier learning towards the end. During test and inference in general, these coefficients are set to 0.5 to equally weight the branches.

While the authors carried out typical performance tests, comparing their proposed framework against previous ones, with error rate as the metric of choice, they ran additional tests to understand why theirs had such a competitive advantage compared to others. They compared sampling techniques for training, how to vary the coefficient in the cumulative learning strategy, and the quality of learning representations, showing either an advantage or close to the best for all three. Finally, they compared the L2 norm of all the weights between the branch output and softmax, demonstrating that by combining the branches, the weights connecting the network to class prediction are equally weighted compared to previous frameworks, helping further achieve better performance in long-tailed classes.